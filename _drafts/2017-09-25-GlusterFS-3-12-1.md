---
published: false
---

We're in the process of shifting from using our [custom 'glue'][1] for orchestrating Docker deployments to Kubernetes.

Part of this is to replace our legacy NFS file servers used to host uploads / attachments and static files for our web applications.

While NFS(v4) performance is adequate, it is a clear single point of failure and of course, there are the age old stale mount problems should network interruptions occur.

I spend some time evaluating various cluster filesystems / network block storage and the two that stood out were Ceph and Gluster.

I settled on Gluster as the most suitable for our needs, it's far less complex to deploy than Ceph, it has less moving pieces and files are stored in a familiar manner on hosts.

## Implementation

I've settled on a 3 node deployment with one node as an [arbiter](http://docs.gluster.org/en/latest/Administrator%20Guide/arbiter-volumes-and-quorum/) (replica 3, arbiter 1).

Our nodes are CentOS 7 VMs within our exiting XenServer infrastructure, each node has 8 vCPUs [Xeon E5-2680 v4](https://ark.intel.com/products/91754/Intel-Xeon-Processor-E5-2680-v4-35M-Cache-2_40-GHz), 16GB of RAM and backed by our [iSCSI SSD Storage](https://smcleod.net/tech/ssd-storage-cluster-diagram/).

## Automation / Puppet

We're long time, heavy users of Puppet so naturally I'm deploying Gluster via a [Puppet module](https://github.com/voxpupuli/puppet-gluster) and generating volumes and volume configuration from [Hiera](https://docs.puppet.com/hiera/).

Volumes are automatically generated from the Hiera structure that defines our applications.

{% highlight yaml %}
# profiles::services::gluster::volume:
profiles::services::gluster::volume::pool: "%{alias('profiles::services::gluster::host::pool')}"
profiles::services::gluster::volume::pool_members: "%{alias('profiles::services::gluster::host::pool_members')}"
profiles::services::gluster::volume::brick_mountpoint: '/mnt/gluster-storage'
profiles::services::gluster::volume::replica: 3
profiles::services::gluster::volume::arbiter: 1
profiles::services::gluster::volume::volume_options:
  # Failover clients after 10 seconds of a server being unavailable
  'network.ping-timeout': '10'
  'cluster.lookup-optimize': 'true'
  'cluster.readdir-optimize': 'true'
  'cluster.use-compound-fops': 'true'
  'performance.parallel-readdir': 'true'
  'performance.client-io-threads': 'true'
  'performance.stat-prefetch': 'true'
  'diagnostics.brick-log-level': 'WARNING'
  'diagnostics.client-log-level': 'WARNING'
  'server.event-threads': '3'
  'client.event-threads': '3'
{% endhighlight %}

I enabled the `nis_enabled` SEbool to prevent a number of SELinux denials I noticed in the logs:

{% highlight yaml %}
profiles::os::redhat::centos7::selinux::selinux_booleans:
  'nis_enabled':
    value: 'on'
{% endhighlight %}

I also increased the local emepheral port range and the kernel's socket backlog limit as suggested by Redhat:

{% highlight yaml %}
sysctl::base::values:
  'net.ipv4.tcp_max_syn_backlog':
    ensure: present
    value: '4096'
    comment: 'Increase syn backlogs for gluster'
  'net.ipv4.ip_local_port_range':
    ensure: present
    value: '32768 65535'
    comment: 'Increase local port range for gluster'
  'net.core.somaxconn':
    ensure: present
    value: '2048'
    comment: 'Increase kernel socket backlog limit for gluster'
{% endhighlight %}

## Performance

Performance is, well, very poor for anything other than large reads.

I was expecting a hit to IOP/s performance as you would with any clustered, network file system, but I wasn't expecting it to drop as much as it did, especially after enabling the above performance options on the volumes.

TODO - Insert benchmarks and graphs here.

## Annoyances

### Open Files

Gluster seems to love open file handles, on an average node in the cluster with 120 small volumes connected to 3 fuse clients and no files I often see up to 1.5 _million_ open files:

{% highlight shell %}
root@int-gluster-02:~  # lsof | wc -l
1042782

root@int-gluster-01:~  # netstat -lnp|grep gluster|wc -l
111
{% endhighlight %}

### Inconsistant Configuration

A big gripe I have is with the location of cluster and volume configuration, it is kept in a number of different files and file locations, for example:

{% highlight shell %}
/etc/glusterfs/glusterd.vol
/var/lib/glusterd/options
/var/lib/glusterd/glusterd.info
/var/lib/glusterd/vols/simpleapp_static/quota.conf
/var/lib/glusterd/vols/simpleapp_static/trusted-simpleapp_static.tcp-fuse.vol
/var/lib/glusterd/vols/simpleapp_static/bricks/int-gluster-01\:-mnt-gluster-storage-simpleapp_static
{% endhighlight %}

This makes managing the cluster and volumes with automation tools a bit of a pain and thus most tooling calls out to the `gluster` command line application to set and read configuration which is not ideal.

### Memory Usage & Leaks

Along the way with Gluster from version 3.10 to 3.12 I've encountered _many_ memory leaks resulting in OOMs, corrupt volume configuration and often entire cluster rebuilds.

A lot of these seem to occur when making a large number of changes to volume configuration.

Often when Gluster runs out of memory and gets OOM killed, it corrupts `.vol` or `.info` files in `/var/lib/glusterd/vols/<volumes>/`, this causes the daemon to fail to start, requires you to hunt through logs for mentions of incorrectly configured volumes, delete the files in question and hope that they correctly sync back from another node, if they don't or can't be synced back it seems you might have to destroy the volumes (or cluster) and recreate them before restoring your (brick) data from backups - this is not at all fun.

### Poor Gluster CLI Performance

Again, because of the nature of cluter and volume configuration automation often has to call out to use the Gluster CLI tool to set or get information, this is made especially painful due to the tools performance - notibly how long it takes to set / get options on volumes.

Setting a volume option on average takes around 1 second and the tool cannot set an option on multiple volumes at once.

This quickly adds up, suppose you have 200 volumes and you're setting 5 options on each volume, `200*5=1000 / 60` - that's _16.6 minutes just to set the options!_, this could be a real issue when recovering from a disaster scenario.

### Broken Links to Gluster.org and Gluster.readthedocs.io

Many times I've clicked on links to Gluster articles or documentation and have found them to be broken, it seems that Gluster.org has undergone changes and has not created redirects for existing permalinks.

## Notes

[1] When we first deployed Docker to replace LXC and our legacy Puppet-heavy application configuration and deployment systems there really wasn't any existing tool to manage this, thus we rolled our own, mainly a few Ruby scripts combined with a Puppet / Hiera / Mcollective driven workflow.